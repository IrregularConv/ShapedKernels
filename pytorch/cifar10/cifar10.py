# -*- coding: utf-8 -*-
"""cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TZBTD-JDX_B6RToOm6hX1GEUtCqEuJ1w
"""

import torch
from torch import Tensor
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import time

import matplotlib.pyplot as plt
import numpy as np

from IrregularResNet import ResNet, Bottleneck, BasicBlock

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#device = torch.device("cpu")
# print(device)


# Load dataset for training and testing
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 32

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, pin_memory=True,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)


classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

torch.cuda.empty_cache()
irregular = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=10, use_mask=True)

net = irregular.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(irregular.parameters(), lr=0.001, momentum=0.9)

print("Training start")

irregular_l = []
start_time = time.time()
for epoch in range(20):  # loop over the dataset multiple times

    total_loss = 0
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]

        # zero the parameter gradients
        optimizer.zero_grad()
        inputs, labels = data
        # forward + backward + optimize
        outputs = irregular(inputs.to(device))
        loss = criterion(outputs, labels.to(device))
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        total_loss += loss.item()
        if i % 50 == 49:    # print every 200 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
    irregular_l += [total_loss / i]
    if epoch % 5 == 4:
        np.savetxt("irregular_losses.csv", 
           irregular_l,
           delimiter =", ", 
           fmt ='% s')

        PATH = './cifar_irregular_resnet'
        torch.save(irregular.state_dict(), PATH)

print('Finished Training in time ', time.time() -start_time)

np.savetxt("irregular_losses.csv", 
           irregular_l,
           delimiter =", ", 
           fmt ='% s')

PATH = './cifar_irregular_resnet'
torch.save(irregular.state_dict(), PATH)